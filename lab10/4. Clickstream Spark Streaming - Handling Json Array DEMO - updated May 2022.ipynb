{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Json Array streaming from Kafka\n",
    "Here, we have some instructions on how to handle array of json. Make sure your <b>Kafka Producer</b> is publishing an Array of objects.\n",
    "\n",
    "<b>Revised by Chee-Ming Ting, 5 May 2022</b>: \n",
    "This demo uses LT2-Producer to generate and publish data, where \"Clicks\" and \"'Impressions\" data are sent in String type. \n",
    "Therefore, the defined schema used in the from_jason should match the String type.\n",
    "\n",
    "The from_json() function has a constrait to be followed to convert column value to a dataframe:\n",
    "<b>Whatever datatype you define in the schema should match with the value present in the json, if there is any column's mismatch value leads to null in all column values.</b>\n",
    "\n",
    "\n",
    "### Step 1 : Initialize Spark Session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.0.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0 pyspark-shell'\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Clickstream Analysis in Spark\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Read Stream from the Kafka Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"clickstream\"\n",
    "\n",
    "#configuration\n",
    "hostip = \"10.156.3.124\" #change me\n",
    "\n",
    "df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", f'{hostip}:9092') \\\n",
    "  .option(\"subscribe\", topic) \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Schema and Parsing the data\n",
    "Here, since we are receiving data as an <strong>array</strong> compared with a single object in the previous example, we need to use <code>ArrayType</code> while defining our schema.\n",
    "\n",
    "Before Running this, make sure that the <strong>LT2-Producer.ipynb</strong> is producing data in the following or similar format:\n",
    "<code>\n",
    "[{'Clicks': 0, 'Impressions': 3, 'ts': 1603072527}, {'Clicks': 0, 'Impressions': 3, 'ts': 1603072527}, {'Clicks': 0, 'Impressions': 3, 'ts': 1603072527}, {'Clicks': 0, 'Impressions': 3, 'ts': 1603072527}, {'Clicks': 0, 'Impressions': 11, 'ts': 1603072527}, {'Clicks': 1, 'Impressions': 11, 'ts': 1603072527}]\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the schema for the structured datastream received\n",
    "# schema = ArrayType(StructType([    \n",
    "#     StructField('Clicks', IntegerType(), True), \n",
    "#     StructField('Impressions', IntegerType(), True),\n",
    "#     StructField('ts', TimestampType(), True)            \n",
    "# ]))\n",
    "\n",
    "# Since \"Clicks\" and \"'Impressions\" sent from LT2-Producer in string type, \n",
    "# ensure data type defined in schema to match the string type when using the from_json\n",
    "# \"Clicks\" and \"'Impressions\" can be coverted back to int type later\n",
    "schema = ArrayType(StructType([    \n",
    "    StructField('Clicks', StringType(), True), \n",
    "    StructField('Impressions', StringType(), True),\n",
    "    StructField('ts', TimestampType(), True)            \n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(F.from_json(F.col(\"value\").cast(\"string\"), schema).alias('parsed_value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- parsed_value: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- Clicks: string (nullable = true)\n",
      " |    |    |-- Impressions: string (nullable = true)\n",
      " |    |    |-- ts: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can notice the schema above, the <strong>Columns</strong> are nested. We can use the <code>explode</code> function to flatten it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(F.explode(F.col(\"parsed_value\")).alias('unnested_value'))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- unnested_value: struct (nullable = true)\n",
      " |    |-- Clicks: string (nullable = true)\n",
      " |    |-- Impressions: string (nullable = true)\n",
      " |    |-- ts: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the <strong>.explode()</strong>, the schema looks normal again, we can now proceed with the rest of the operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formatted = df.select(\n",
    "                    F.col(\"unnested_value.Clicks\").alias(\"Clicks\"),\n",
    "                    F.col(\"unnested_value.Impressions\").alias(\"Impressions\"),\n",
    "                    F.col(\"unnested_value.ts\").alias(\"ts\")\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Clicks: string (nullable = true)\n",
      " |-- Impressions: string (nullable = true)\n",
      " |-- ts: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_formatted.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert columns \"Clicks\" & \"Impressions\" back to integer type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formatted = df_formatted.withColumn(\"Clicks\", F.col(\"Clicks\").cast(\"int\")).withColumn(\"Impressions\", F.col(\"Impressions\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Clicks: integer (nullable = true)\n",
      " |-- Impressions: integer (nullable = true)\n",
      " |-- ts: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_formatted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_formatted = df_formatted \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_formatted.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the .minute function, we can perform the following aggregation \n",
    "grouped_by_min = df_formatted.groupBy(F.minute(\"ts\").alias(\"minute_bin\"))\\\n",
    "                    .agg(F.sum(\"Impressions\").alias(\"Total Impressions\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- minute_bin: integer (nullable = true)\n",
      " |-- Total Impressions: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_by_min.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_group = grouped_by_min \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"impressions_minute_bin\") \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|minute_bin|Total Impressions|\n",
      "+----------+-----------------+\n",
      "|        12|               20|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from impressions_minute_bin\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_group.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
